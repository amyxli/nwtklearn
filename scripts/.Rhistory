#   banditTrial      0.003188   0.001540   2.070  0.03847 *
# now for the optim cond
## relevel for analysis
trialdatOptim$infoCond <- as.factor(trialdatOptim$infoCond)
trialdatOptim$infoCond <-relevel(trialdatOptim$infoCond, ref = "noninfo") # set as noninfo for glm, info for emmeans
mod_optim <- glmer(choice ~ infoCond + banditTrial + (1|PID),
data = trialdatOptim,
family = binomial(link = "logit"),
nAGQ = 0)
summary(mod_optim) ## infoCond ns (p=0.957), banditTrial sig
confint(pairs(emmeans(mod_optim, ~ infoCond,type="response")))
# now for the sub cond
trialdatSub$infoCond <- as.factor(trialdatSub$infoCond)
trialdatSub$infoCond <-relevel(trialdatSub$infoCond, ref = "info") # set as noninfo for glm, info for emmeans
mod_sub <- glmer(choice ~ infoCond + banditTrial + (1|PID),
data = trialdatSub,
family = binomial(link = "logit"),
nAGQ = 0)
summary(mod_sub) ## infoCond significant (p=0.00506), banditTrial sig
confint(pairs(emmeans(mod_sub, ~ infoCond,type="response")))
# Value estimates from block 4 ####
block4Ests <- data %>% filter(!is.na(banditTrial)) %>%
select(c(PID, infoCond, optimCond,
subStim, optStim,
block, banditTrial, choice, feedback,
choiceName,
leftOption, rightOption,
leftInput, rightInput)) %>%
filter(block == 4)
block4Ests <- block4Ests %>% # convert into long format
pivot_longer(cols = leftInput:rightInput,
names_to = "estimateFor") %>%
mutate(estOption = case_when(
estimateFor == "leftInput" ~ leftOption,
estimateFor == "rightInput" ~ rightOption,
TRUE ~ ""
))
block4Ests <- block4Ests %>%
mutate(
optOptimality = case_when(estOption == optStim ~ "optim",
estOption == subStim ~ "sub",
TRUE ~ "NA")
)
block4Ests <- block4Ests %>%
select(c(PID, infoCond, optimCond, block, banditTrial, estOption, optOptimality, value))
choiceNameData$estOption <- choiceNameData$choiceName # use our choice name df to mark estimated option as target or not
tmp <- full_join(block4Ests, choiceNameData, by = c("PID", "estOption")) %>%
mutate(optionType = ifelse(choice == 1, "target", "non-target"))
block4Ests <- tmp %>%
select(c(PID, infoCond, optimCond, block, banditTrial, estOption, optionType, optOptimality, value))
# need to clean some values as people accidentally put in apostrophe, etc
block4Ests$value <- gsub("%$","", block4Ests$value)
block4Ests$value <- gsub("`$","", block4Ests$value)
block4Ests$value <- gsub("'$","", block4Ests$value)
block4Ests$value <- str_replace(block4Ests$value, "o", "0") #replace os with 0s
block4Ests$value <- str_replace(block4Ests$value, "o", "0") #and again
block4Ests$value <- as.numeric(block4Ests$value)
block4Ests$condition <- paste0(block4Ests$infoCond, ", ", block4Ests$optimCond)
## Exclusion criteria  ####
### Reported in manuscript ####
# remove estimates with estimates 1000 or higher
block4Ests_postExcl <- block4Ests %>% filter(value < 1000) # remove estimates 1000 or over
# see how many estimates were removed
(nrow(block4Ests)-nrow(block4Ests_postExcl))/nrow(block4Ests)
# remove rows with 0 estimates
block4excl2 <- subset(block4Ests_postExcl, value == 0)$PID %>% unique() # identify these participants
block4Excl0Rows <- block4Ests_postExcl %>% filter(value == 0)
block4Ests_postExcl <- block4Ests_postExcl %>% filter(value > 0) # for estimates of 0, remove that row only rather than whole subject
# see how many estimates were removed
(nrow(block4Ests)-nrow(block4Ests_postExcl))/nrow(block4Ests)
library(lme4)
library(lmerTest)
block4Ests_postExcl$infoCond <- as.factor(block4Ests_postExcl$infoCond)
block4Ests_postExcl$infoCond <-relevel(block4Ests_postExcl$infoCond, ref = "noninfo")
### for eq optimCond ####
block4mod_eq <- lmer(value ~ infoCond*optionType + (1|PID),
data = subset(block4Ests_postExcl, optimCond == "eq"),
REML = FALSE)
summary(block4mod_eq)
#### for opt optimCond ####
block4mod_opt <- lmer(value ~ infoCond*optionType + (1|PID),
data = subset(block4Ests_postExcl, optimCond == "optim"),
REML = FALSE)
summary(block4mod_opt)
# Fixed effects:
# (Intercept)                     89.902      6.773   57.580  13.273  < 2e-16 ***
#   infoCondinfo                     7.848      9.548   56.664   0.822  0.41454
# optionTypetarget                25.221      3.297 2280.417   7.648 2.98e-14 ***
#   infoCondinfo:optionTypetarget  -12.964      4.544 2270.207  -2.853  0.00437 **
#### for sub optimCond ####
block4mod_sub <- lmer(value ~ infoCond*optionType + (1|PID),
data = subset(block4Ests_postExcl, optimCond == "sub"),
REML = FALSE)
summary(block4mod_sub)
# Fixed effects:
#   Estimate Std. Error       df t value Pr(>|t|)
# (Intercept)                   109.9467     1.8878  29.4332  58.241   <2e-16 ***
#   infoCondinfo                   -0.4856     2.5561  29.4332  -0.190    0.851
# optionTypetarget              -25.0800     1.3914 638.0000 -18.025   <2e-16 ***
#   infoCondinfo:optionTypetarget  -1.3811     1.8840 638.0000  -0.733    0.464
## AFTER
# (Intercept)                      114.958      4.453  146.774  25.817  < 2e-16 ***
#   infoCondinfo                    -9.235      6.307  147.823  -1.464   0.1452
# optionTypetarget                 -25.082      3.776 2336.106  -6.643 3.81e-11 ***
#   infoCondinfo:optionTypetarget   11.388      5.287 2331.637   2.154   0.0314 *
##### get means
tmp<-subset(block4Ests_postExcl, optimCond == "sub" & optOptimality == "sub")
tmp %>% group_by(infoCond) %>% summarise(mean(value))
# infoCond `mean(value)`
# <fct>            <dbl>
#   1 noninfo           85.1
# 2 info              86.8
## now process data to be visualised ####
block4Ests_postExcl_backup <- block4Ests_postExcl
block4Ests_postExcl$optOptimality <- as.factor(block4Ests_postExcl$optOptimality)
block4Ests_postExcl$optionType <- as.factor(block4Ests_postExcl$optionType)
block4Ests_postExcl$infoCond <-relevel(block4Ests_postExcl$infoCond, ref = "info")
block4Summary_noEq <- block4Ests_postExcl %>% # subject level averaging
filter(optimCond != "eq") %>%
group_by(PID, condition, optOptimality, infoCond, optimCond) %>%
summarise(avgValue = mean(value))
block4Summary_noEq <- block4Summary_noEq %>% # group level averaging
group_by(condition, optOptimality, infoCond, optimCond) %>%
summarise(stdev = sd(avgValue, na.rm=TRUE),
mean = mean(avgValue, na.rm=TRUE),
n = n(),
stderr = stdev/sqrt(n)) %>%
ungroup()
block4Summary_eq <- block4Ests_postExcl %>% # subject level averaging
filter(optimCond == "eq") %>%
group_by(PID, condition, estOption, infoCond, optimCond, optionType) %>%
summarise(avgValue = mean(value))
block4Summary_eq <- block4Summary_eq %>% # group level averaging
group_by(infoCond, optimCond, optionType) %>%
summarise(stdev = sd(avgValue, na.rm=TRUE),
mean = mean(avgValue, na.rm=TRUE),
n = n(),
stderr = stdev/sqrt(n)) %>%
ungroup()
## Visualise ####
block4Summary_noEq$optOptimality <- factor(block4Summary_noEq$optOptimality, levels = c("sub", "optim"),
labels = c("Suboptimal Option (M = 80)", "Optimal Option (M = 120)") # TO DO: think of a better label as this doesn't make sense for eq
)
block4Summary_noEq_optim <- block4Summary_noEq %>% filter(optimCond == "optim")
block4Summary_noEq_sub<- block4Summary_noEq %>% filter(optimCond == "sub")
ggplot(block4Summary_noEq_optim, aes(x=infoCond, y=mean, col = infoCond)) +
geom_point(size = 3, position = position_dodge(width = 1)) +
geom_errorbar(aes(ymin=mean - stderr, ymax = mean + stderr), width = .1, position = position_dodge(width = 1)) +
theme_bw() +
coord_cartesian(ylim = c(80,130))+
labs(title = "Target optimal", y="Mean Estimate for 'Win' Trials") +
scale_colour_colorblind(name = "Informativeness Condition", labels = c("Informative", "Non-Informative")) +
scale_x_discrete(name = "Informativeness Condition", labels = c("Informative", "Non-Informative"))+
facet_grid(~optOptimality)
#ggsave(here("plots","s2_block4est_noEq_optim.jpg"), width = 6, height = 4)
ggplot(block4Summary_noEq_sub, aes(x=infoCond, y=mean, col = infoCond)) +
geom_point(size = 3, position = position_dodge(width = 1)) +
geom_errorbar(aes(ymin=mean - stderr, ymax = mean + stderr), width = .1, position = position_dodge(width = 1)) +
theme_bw() +
coord_cartesian(ylim = c(80,130))+
labs(title = "Target suboptimal", y="Mean Estimate for 'Win' Trials") +
scale_colour_colorblind(name = "Informativeness Condition", labels = c("Informative", "Non-Informative")) +
scale_x_discrete(name = "Informativeness Condition", labels = c("Informative", "Non-Informative"))+
facet_grid(~optOptimality)
#ggsave(here("plots","s2_block4est_noEq_sub.jpg"), width = 6, height = 4)
block4Summary_eq$optionType <- factor(block4Summary_eq$optionType, levels = c("non-target", "target"),
labels = c("Non-Target Option (M = 100)", "Target Option (M = 100)") # TO DO: think of a better label as this doesn't make sense for eq
)
ggplot(block4Summary_eq, aes(x=infoCond, y=mean, col = infoCond)) +
geom_point(size = 3, position = position_dodge(width = 1)) +
geom_errorbar(aes(ymin=mean - stderr, ymax = mean + stderr), width = .1, position = position_dodge(width = 1)) +
geom_hline(yintercept = 100, linetype = "dashed", color = "black") +  # Adding the dotted line
theme_bw() +
coord_cartesian(ylim = c(80,120))+
labs(title="Target & non-target equal", y="Mean Estimate for 'Win' Trials", x = "Option") +
scale_colour_colorblind(name = "Informativeness Condition", labels = c("Informative", "Non-Informative")) +
scale_x_discrete(name = "Informativeness Condition", labels = c("Informative", "Non-Informative"))+
facet_grid(~optionType)
#ggsave(here("plots","s2_block4est_eq"), width = 7, height = 4)
# Value estimates from repeated estimates ####
# Value estimates from repeated estimates ####
repeatEsts <- data %>% filter(grepl("undefined", responses) & postQ != "") %>%
select(c(PID, infoCond, optimCond, optStim, subStim, responses, postQ))
repeatEsts$condition <- paste0(repeatEsts$infoCond, ", ", repeatEsts$optimCond)
repeatEsts$responses <- as.numeric(gsub(".*?([0-9]+).*", "\\1", repeatEsts$responses))   #extract numbers only
# Mark whether or not the estimate option was a target or non-target
choiceNameData$postQ <- choiceNameData$choiceName # use our choice name df to mark estimated option as target or not
tmp <- full_join(repeatEsts, choiceNameData, by = c("PID", "postQ")) %>%
mutate(optionType = ifelse(choice == 1, "target", "non-target"))
repeatEsts <- tmp %>%
select(c(PID, infoCond, optimCond, condition, postQ, optionType, optStim, subStim, responses))
## Exclusions ####
### As reported in manuscript ####
# 1) exclude extremely high estimates
#repeatExcl1_ids <- subset(repeatEsts, responses >= 1000)$PID %>% unique() # just 1 person
repeatEsts_postExcl <- repeatEsts %>% filter(responses < 1000)
(nrow(repeatEsts)-nrow(repeatEsts_postExcl))/nrow(repeatEsts)
# 2) exclude people who didn't report 0s AND non-0s for either of the 2 options?
repeatEsts_postExcl$PID <- as.factor(repeatEsts_postExcl$PID) # change data type for grouping
repeatEsts_nZero <- repeatEsts_postExcl %>%
group_by(PID,postQ, .drop=FALSE) %>%
count(responses == 0) %>%  # count number of 0 responses out of 10 estimates for each postQ (option); and do same for non-0s
arrange(PID, postQ, `responses == 0`) %>%
summarise(count = n()) # each participant should have count "2" for each postQ, if correctly following instructions to report 0s and non-0s
# PID   postQ                    `responses == 0`     n
# <fct> <chr>                    <lgl>            <int>
# 1 42    imgNWTK/FindOutNow.jpg   FALSE               10
# 2 42    imgNWTK/KeepItSecret.jpg FALSE                5
# 3 42    imgNWTK/KeepItSecret.jpg TRUE                 5
# # THEN WHEN SUMMARISING
# PID   postQ                    count
# <fct> <chr>                    <int>
# 1 42    imgNWTK/FindOutNow.jpg       1
# 2 42    imgNWTK/KeepItSecret.jpg     2
# participants who didn't report 0s AND non-0s for one or both of the 2 options
repeatExcl2 <- subset(repeatEsts_nZero, count < 2)$PID
repeatExcl2_ids <- repeatExcl2 %>% unique()
# now pick out only the unique ones
repeatExcl2_ids <- as.numeric(as.character(repeatExcl2_ids)) # convert variable type for subsetting later
repeatEsts_postExcl <- subset(repeatEsts_postExcl, !(PID %in% repeatExcl2_ids)) # remove these participants
nonDuplicates <- sapply(repeatExcl2_ids, function(x) x < 191293823) # remember that during preprocessing, we added 191293823 to PIDs of duplicate IDs
length(repeatExcl2_ids[nonDuplicates]) # 91 participants excluded due to not reporting both 0s and non-0s
repeatEsts_postExcl_ids <- repeatEsts_postExcl$PID %>% unique() # length 303; 162 actual participants
### Scenario 2: Strict exclusion ####
### SI Scenario 2 (strict exclusion) ####
#
# # Exclude participants who gave a response they could not have observed (this differs by condition)
#
# ## Exclude participants in target & non-target not equal who gave estimates less than 70
# ## or more than 130
# ## For target & non target equal, exclude those who gave estimates less than 90 and more than 110
# repeatEsts <- repeatEsts %>% mutate(
#   minObs = case_when(optimCond == "eq" ~ 90,
#                      .default = 70),
#   maxObs = case_when(optimCond == "eq" ~ 110,
#                      .default = 130)
# )
#
# repeatEsts_strictExcl1 <- subset(repeatEsts, (responses<minObs & responses != 0) | (responses>maxObs & responses != 0))$PID %>% unique()
#
# # Exclude participants did NOT give 0 responses
# # run section on repeatExcl2_ids
#
# # remove people
#
# repeatEsts <- repeatEsts %>% filter(!(PID %in% repeatEsts_strictExcl1) & !(PID %in% repeatExcl2_ids)) # for estimates over 1000, remove the whole subject
#
# repeatEsts$PID %>% unique()
## Compute relative optimality of the given option ####
repeatEsts_postExcl <- repeatEsts_postExcl %>%
mutate(
optOptimality = case_when(postQ == optStim ~ "optim",
postQ == subStim ~ "sub",
TRUE ~ "NA")
)
## Plotting ####
repeatEsts_summary_noEq <- repeatEsts_postExcl %>% # subject level averaging
filter(optimCond != "eq") %>%
group_by(PID, infoCond, optimCond, optOptimality) %>%
summarise(stdev = sd(responses, na.rm=TRUE),
mean = mean(responses, na.rm=TRUE),
n = n(),
stderr = stdev/sqrt(n)) %>%
ungroup()
repeatEsts_summary_noEq <- repeatEsts_summary_noEq %>% # group level averaging
group_by(infoCond, optimCond, optOptimality) %>%
summarise(stdev = sd(mean, na.rm=TRUE),
mean = mean(mean, na.rm=TRUE),
n = n(),
stderr = stdev/sqrt(n)) %>%
ungroup()
repeatEsts_summary_eq <- repeatEsts_postExcl %>% # subject level averaging
filter(optimCond == "eq") %>%
group_by(PID, infoCond, optimCond, optOptimality, optionType) %>%
summarise(stdev = sd(responses, na.rm=TRUE),
mean = mean(responses, na.rm=TRUE),
n = n(),
stderr = stdev/sqrt(n)) %>%
ungroup()
repeatEsts_summary_eq <- repeatEsts_summary_eq %>% # group level averaging
group_by(infoCond, optimCond, optOptimality, optionType) %>%
summarise(stdev = sd(mean, na.rm=TRUE),
mean = mean(mean, na.rm=TRUE),
n = n(),
stderr = stdev/sqrt(n)) %>%
ungroup()
repeatEsts_summary_noEq$optOptimality <- factor(repeatEsts_summary_noEq$optOptimality, levels = c("sub", "optim"),
labels = c("Suboptimal Option (M = 40)", "Optimal Option (M = 60)")
)
repeatEsts_summary_eq$optionType <- factor(repeatEsts_summary_eq$optionType, levels = c("non-target", "target"),
labels = c("Non-Target Option (M = 50)", "Target Option (M = 50)")
)
repeatEsts_summary_noEq_opt <- repeatEsts_summary_noEq %>% filter(optimCond == "optim")
repeatEsts_summary_noEq_sub <- repeatEsts_summary_noEq %>% filter(optimCond == "sub")
ggplot(repeatEsts_summary_noEq_opt, aes(x=infoCond, y=mean, col = infoCond)) +
geom_point(size = 3, position = position_dodge(width = 1)) +
geom_errorbar(aes(ymin=mean - stderr, ymax = mean + stderr), width = .1, position = position_dodge(width = 1)) +
coord_cartesian(ylim = c(35,65))+
theme_bw() +
labs(title = "Target optimal", y="Mean Estimate (Including Both 'Win' and 'No-Win' Trials)") +
scale_colour_colorblind(name = "Informativeness Condition", labels = c("Informative", "Non-Informative")) +
scale_x_discrete(name = "Informativeness Condition", labels = c("Informative", "Non-Informative")) +
facet_grid(~optOptimality)
#ggsave(here("plots","s2_repeatest_noeq_opt_strictExcl.jpg"), width = 6, height = 4)
ggplot(repeatEsts_summary_noEq_sub, aes(x=infoCond, y=mean, col = infoCond)) +
geom_point(size = 3, position = position_dodge(width = 1)) +
geom_errorbar(aes(ymin=mean - stderr, ymax = mean + stderr), width = .1, position = position_dodge(width = 1)) +
coord_cartesian(ylim = c(35,65))+
theme_bw() +
labs(title = "Target suboptimal", y="Mean Estimate (Including Both 'Win' and 'No-Win' Trials)") +
scale_colour_colorblind(name = "Informativeness Condition", labels = c("Informative", "Non-Informative")) +
scale_x_discrete(name = "Informativeness Condition", labels = c("Informative", "Non-Informative")) +
facet_grid(~optOptimality)
#ggsave(here("plots","s2_repeatest_noeq_sub.jpg"), width = 6, height = 4)
ggplot(repeatEsts_summary_eq, aes(x=infoCond, y=mean, col = infoCond)) +
geom_point(size = 3, position = position_dodge(width = 1)) +
geom_errorbar(aes(ymin=mean - stderr, ymax = mean + stderr), width = .1, position = position_dodge(width = 1)) +
coord_cartesian(ylim = c(40,60))+
theme_bw() +
labs(title="Target & non-target equal", y="Mean Estimate (Including Both 'Win' and 'No-Win' Trials)") +
scale_x_discrete(name = "Informativeness Condition", labels = c("Informative", "Non-Informative")) +
scale_colour_colorblind(name = "Informativeness Condition", labels = c("Informative", "Non-Informative")) +
facet_grid(~optionType)
#ggsave(here("plots","s2_repeatest_eq.jpg"), width = 7, height = 4)
## Analyse ####
### for eq optimCond ####
repeatEsts_inds_eq <- repeatEsts_postExcl %>%
filter(optimCond == "eq")
repeatedEsts_eq_mod <- lmer(responses ~ infoCond*optionType + (1|PID), data = repeatEsts_inds_eq, REML = FALSE)
summary(repeatedEsts_eq_mod)
# Fixed effects:
#   Estimate Std. Error        df t value Pr(>|t|)
# (Intercept)                        53.6339     3.3960  196.5940  15.793   <2e-16
# infoCondnoninfo                    -3.8251     4.6923  196.1339  -0.815    0.416
# optionTypetarget                   -0.2791     4.4631 1234.1960  -0.063    0.950
# infoCondnoninfo:optionTypetarget    1.6232     6.1686 1234.1242   0.263    0.792
### for optim optimCond ####
repeatEsts_inds_optim <- repeatEsts_postExcl %>%
filter(optimCond == "optim")
repeatEsts_optim_mod <- lmer(responses ~ infoCond*optionType + (1|PID), data = repeatEsts_inds_optim, REML=FALSE)
summary(repeatEsts_optim_mod)
# Fixed effects:
#                                       Estimate Std. Error   df t value Pr(>|t|)
# (Intercept)                          45.716      3.619  143.922  12.632  < 2e-16 ***
#   infoCondnoninfo                    -5.809      5.160  143.922  -1.126  0.26214
#   optionTypetarget                   12.942      4.307 1159.000   3.005  0.00271 **
#   infoCondnoninfo:optionTypetarget    1.828      6.141 1159.000   0.298  0.76601
#### means ####
### for sub optimCond ####
repeatEsts_inds_sub <- repeatEsts_postExcl %>%
filter(optimCond == "sub")
repeatEsts_sub_mod <- lmer(responses ~ infoCond*optionType + (1|PID), data = repeatEsts_inds_sub, REML = FALSE)
summary(repeatEsts_sub_mod)
repeatEsts_sub_mod <- lm(responses ~ infoCond*optionType, data = repeatEsts_inds_sub)
summary(repeatEsts_sub_mod)
repeatEsts_inds_sub %>% group_by(infoCond, optionType) %>% get_summary_stats()
# Fixed effects:
#                                   Estimate Std. Error        df t value Pr(>|t|)
# (Intercept)                        53.7194     3.1831  190.5025  16.876   <2e-16 ***
#   infoCondnoninfo                     0.9572     4.7213  190.5025   0.203   0.8396
# optionTypetarget                   -2.7944     4.1224 1254.0000  -0.678   0.4980
# infoCondnoninfo:optionTypetarget  -11.9756     6.1145 1254.0000  -1.959   0.0504 .
# Assessing relationship between people's estimates and their choices in the task ####
## Relationship between block 4 estimates and target choices ####
## first compute the means for each participant
block4Ests_subj_means <- block4Ests_postExcl %>%
group_by(PID, condition, optionType) %>%
summarise(meanEstimate = mean(as.numeric(value)))
## compute the difference in estimates for target vs non-target
block4Ests_difference <- pivot_wider(block4Ests_subj_means, values_from = meanEstimate, names_from = optionType) %>%
mutate(difference = target - `non-target`)
## calculate mean preference for FON/target
propFON_avg_PID <- propFON_blocks %>%
group_by(PID) %>%
summarise(P_FON = mean(percent_FON))
block4ests_choiceFON <- merge(block4Ests_difference, propFON_avg_PID)
# note that here, the data has two copies of the noninformative, unequal participants due to
# the dummy participants (identifiable via their IDs over 191293823) who we added in for
# between-group comparisons!
# remove them from this analysis
block4ests_choiceFON <- block4ests_choiceFON %>% filter(PID < 191293823)
## plot
block4_choice_plot_data <- block4ests_choiceFON %>%
rename(P_Target = P_FON)
block4ets_choice_plot <- ggplot(block4_choice_plot_data, aes(x = difference, y = P_Target, col = condition))+
geom_point()+
geom_smooth(method = "lm", se = FALSE)+
theme_bw()+
labs(x = "Target Estimate - NonTarget Estimate", y = "Target Choices %")+
theme(axis.title = element_text(size = 18, face = "bold"), legend.title = element_blank()); block4ets_choice_plot
block4ets_choice_plot
##lm
tmp_lm_block4 <- lm(P_FON ~ difference + 1,block4ests_choiceFON)
summary(tmp_lm_block4)
block4ests_choiceFON$PID
## Relationship between repeated post-test estimates and target choices ####
# compute subject means from posttest estimates for each of the two items
repeatEsts_subj_means <- repeatEsts_postExcl %>%
group_by(PID, condition, optionType) %>%
summarise(estimate_mean = mean(responses)) %>%
filter(!is.na(optionType))
# compute difference in estimates for target vs nontarget for each participant
repeatEsts_avg_difference <- pivot_wider(repeatEsts_subj_means, values_from = estimate_mean, names_from = optionType) %>%
mutate(difference = `target` - `non-target`)
# now merge into same dataframe as popFON_avg_PID which contains info about prop target choices during task
repeatEsts_choice <- merge(repeatEsts_avg_difference, propFON_avg_PID) %>%
filter(!is.na(difference))
repeatEsts_choice$PID<-as.numeric((as.character(repeatEsts_choice$PID)))
# note that here, the data has two copies of the noninformative, unequal participants due to
# the dummy participants (identifiable via their IDs over 191293823) who we added in for
# between-group comparisons!
# remove them from this analysis
repeatEsts_choice <- repeatEsts_choice %>% filter(PID < 191293823)
block4ets_choice_plot <- ggplot(block4_choice_plot_data, aes(x = difference, y = P_Target, col = condition))+
geom_point()+
geom_smooth(method = "lm", se = FALSE)+
theme_bw()+
labs(x = "Target Estimate - NonTarget Estimate", y = "Target Choices %")+
theme(axis.title = element_text(size = 18, face = "bold"), legend.title = element_blank()); block4ets_choice_plot
block4ets_choice_plot
tmp_lm_block4 <- lm(P_FON ~ difference + 1,block4ests_choiceFON)
summary(tmp_lm_block4)
block4ests_choiceFON$PID
summary(tmp_lm_block4)
tmp_lm_block4 <- lm(P_FON ~ difference + 1 + condition*difference,block4ests_choiceFON)
summary(tmp_lm_block4)
tmp_lm_block4 <- lm(P_FON ~ difference + 1 + condition,block4ests_choiceFON)
summary(tmp_lm_block4)
block4ests_choiceFON$condition
##lm
block4ests_choiceFON$condition <- as.factor(block4ests_choiceFON$condition)
block4ests_choiceFON$condition
relevel(block4ests_choiceFON$condition, ref = 'noninfo, eq') # make non-info eq the reference
block4ests_choiceFON$condition<-relevel(block4ests_choiceFON$condition, ref = 'noninfo, eq') # make non-info eq the reference
tmp_lm_block4 <- lm(P_FON ~ difference + 1 + condition,block4ests_choiceFON)
summary(tmp_lm_block4)
# compute subject means from posttest estimates for each of the two items
repeatEsts_subj_means <- repeatEsts_postExcl %>%
group_by(PID, condition, optionType) %>%
summarise(estimate_mean = mean(responses)) %>%
filter(!is.na(optionType))
# compute difference in estimates for target vs nontarget for each participant
repeatEsts_avg_difference <- pivot_wider(repeatEsts_subj_means, values_from = estimate_mean, names_from = optionType) %>%
mutate(difference = `target` - `non-target`)
# now merge into same dataframe as popFON_avg_PID which contains info about prop target choices during task
repeatEsts_choice <- merge(repeatEsts_avg_difference, propFON_avg_PID) %>%
filter(!is.na(difference))
repeatEsts_choice$PID<-as.numeric((as.character(repeatEsts_choice$PID)))
# note that here, the data has two copies of the noninformative, unequal participants due to
# the dummy participants (identifiable via their IDs over 191293823) who we added in for
# between-group comparisons!
# remove them from this analysis
repeatEsts_choice <- repeatEsts_choice %>% filter(PID < 191293823)
## plot
repeatEsts_choice$PID <- as.factor(as.character(repeatEsts_choice$PID))
repeatEsts_choice_plot <- ggplot(repeatEsts_choice, aes(x = difference, y = P_FON, col = condition))+
geom_point()+
geom_smooth(method = "lm", se = FALSE)+
theme_bw()+
labs(x = "Target Estimate - NonTarget Estimate", y = "Target Choices %")+
theme(axis.title = element_text(size = 18, face = "bold"), legend.title = element_blank()); repeatEsts_choice_plot
repeatEsts_choice_plot
# compute subject means from posttest estimates for each of the two items
repeatEsts_subj_means <- repeatEsts_postExcl %>%
group_by(PID, condition, optionType) %>%
summarise(estimate_mean = mean(responses)) %>%
filter(!is.na(optionType))
# compute difference in estimates for target vs nontarget for each participant
repeatEsts_avg_difference <- pivot_wider(repeatEsts_subj_means, values_from = estimate_mean, names_from = optionType) %>%
mutate(difference = `target` - `non-target`)
# now merge into same dataframe as popFON_avg_PID which contains info about prop target choices during task
repeatEsts_choice <- merge(repeatEsts_avg_difference, propFON_avg_PID) %>%
filter(!is.na(difference))
repeatEsts_choice$PID<-as.numeric((as.character(repeatEsts_choice$PID)))
# note that here, the data has two copies of the noninformative, unequal participants due to
# the dummy participants (identifiable via their IDs over 191293823) who we added in for
# between-group comparisons!
# remove them from this analysis
repeatEsts_choice <- repeatEsts_choice %>% filter(PID < 191293823)
## plot
repeatEsts_choice$PID <- as.factor(as.character(repeatEsts_choice$PID))
repeatEsts_choice$condition <- as.factor(repeatEsts_choice$condition)
repeatEsts_choice$condition
repeatEsts_choice$condition<-relevel(repeatEsts_choice$condition, ref = 'noninfo, eq') # make non-info eq the reference
repeatEsts_choice$condition
repeatEsts_choice_plot <- ggplot(repeatEsts_choice, aes(x = difference, y = P_FON, col = condition))+
geom_point()+
geom_smooth(method = "lm", se = FALSE)+
theme_bw()+
labs(x = "Target Estimate - NonTarget Estimate", y = "Target Choices %")+
theme(axis.title = element_text(size = 18, face = "bold"), legend.title = element_blank()); repeatEsts_choice_plot
repeatEsts_choice_plot
repeatEsts_lm <- lm(P_FON ~ difference + 1, data= repeatEsts_choice)
repeatEsts_choice$PID
summary(repeatEsts_lm)
repeatEsts_lm <- lm(P_FON ~ difference + 1 + condition, data= repeatEsts_choice)
repeatEsts_choice$PID
summary(repeatEsts_lm)
# load the libraries
library(tidyverse)
library(here)
library(data.table)
library(ggthemes)
# load in the data
files <- list.files(path = here("data","exp2"), pattern = "*.csv", full.names = TRUE)
files
# load in the data
files <- list.files(path = here("data","exp2"), pattern = "*.csv", full.names = TRUE)
files
# load in the data
files <- list.files(path = here("data","exp2"), pattern = "*.csv", full.names = TRUE)
files
